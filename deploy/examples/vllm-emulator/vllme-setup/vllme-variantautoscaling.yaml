apiVersion: llmd.ai/v1alpha1
# Optimizing a variant, create only when the model is deployed and serving traffic
# this is for the collector the collect existing (previous) running metrics of the variant.
kind: VariantAutoscaling
metadata:
  # Unique name of the variant
  name: vllme-deployment
  namespace: llm-d-sim
  labels:
    inference.optimization/acceleratorName: A100
# This is essentially static input to the optimizer
spec:
  # OpenAI API compatible name of the model
  modelID: default/default
  # Unique identifier for this variant: modelID-accelerator-accCount
  variantID: default-default-A100-1
  # Accelerator type for this variant
  accelerator: "A100"
  # Number of accelerators per replica
  acceleratorCount: 1
  # Add SLOs in configmap, add reference to this per model data
  # to avoid duplication and Move to ISOs when available
  sloClassRef:
    # Configmap name to load in the same namespace as optimizer object
    # we start with static (non-changing) ConfigMaps (for ease of implementation only)
    name: premium
    # Key (modelID) present inside configmap
    key: opt-125m
  # Static profiled benchmarked data for this variant
  variantProfile:
    perfParms:
      decodeParms:
        # Decode parameters for ITL equation: itl = alpha + beta * maxBatchSize
        alpha: "20.58"
        beta: "0.41"
      # Prefill parameters for TTFT equation: ttft = gamma + delta * tokens * maxBatchSize
      prefillParms:
        gamma: "5.2"
        delta: "0.1"
    maxBatchSize: 4
